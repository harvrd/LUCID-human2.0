 Four. Testing. Testing. Okay. Scoot and. Sorry. Oh, halena? Hi. Have you heard of like replica AI before. Basically it's just like this AI app. That like I mean this like website. You can go to that you can talk to this AI chat bot. And it's like your companion. And you can talk to you about your feelings and you can also pay for it to send you nudes. If you're really into that stuff, but yeah, it's pretty crazy. There's actually thousands of users already using this thing and they're very into it, I guess and raises the question. As these language models get really really good. What are the ethics or like, should we be allowed to date like AI girlfriends? Or is that socially acceptable. I feel as if. I personally kind of disagree with the idea of having AI girlfriends or I think I personally wouldn't have an aa girlfriend. And. I think this is a personal decision for me, but I also think there's a lot of broader, ethical and social. Sort of issues that are implications that come with that kind of stuff. It might be creepy. Or maybe even dangerous. There's a lines between human machine relationships. And there might be concerns about the potential for exploitation. And. How we kind of view relationships in the long run. If we kind of. If this becomes something more prevalent. Yeah, give me a specific example. Go off. The time. Like go off what? We. 're the objectification of AI as merely a commodity for personal pleasure. Potentially leading to further objectification and even dehumanization of real individuals. So you're saying like if you date this AI girlfriend, then you're going to dehumanize other people. And not view them as people basically or less. So yeah. I mean that way has like the potential. I mean if we kind of see. In a broader context. If this becomes a bigger and bigger part of our lives. I think that's fair a fair reason. I guess. But I feel like with any new technology. When you have this new thing that affects that negatively affect you in some way, like say games. There's plenty of people who play games very healthily and play it very balance in a balanced way. But there's also some people who don't recognize that if you spend all day on this, you will literally sacrifice everything else in your life. And. Get really unhealthy. Or lose all your real life relationships. To play games right. And I think it's fair that all new technologies will have these kinds of things. It just requires you to be cognizant of how this can affect you. And I think a lot of people can be very cognizant of this and have a very healthy relationship with an AI companion. You would still be able to. Make. Friends in real life. If you. Made the active choice, right. And I think it's a net positive because there's a lot of people. Including Myself. I feel. That sometimes has issues with like they're just struggling with life. And sometimes. They might not a lot of times people just don't have anyone to talk to or like someone else is busy. Or like it just takes a lot of effort also from another person's side to even listen to someone talk about their issues. And like having an AI companion that literally just talks to you at the snap of a finger about anything and helps you think through things. I feel really useful and I think that's a big part of. What an AI girlfriend can do, I guess. Ida IDA. I mean, what do you think. I think it's solved. Oh, yeah? So start a new one.    Dude I can't grab. Okay. I got it.  I think the hand tracking is off. Right now the hand checking is really off right now.  Did you get useful clips. So far, I think so. Yes. Okay. Get the. Try to grab like right next to it or something, because one hand is probably the red thing, right. Okay. Back to what we found out. So I think that I definitely think that what you say makes a lot of sense that these companions can offer a lot value to society, especially for people who just don't really have anyone else to talk to. But I think it's still important to be aware of. The potential ethical concerns implications of objectifying AI as near commodities for personal for personal pleasure. And maybe it's possible to maintain real life connections and relationships even with this. And I mean, people definitely had their concerns about gaming and that impacts on your social life and not every gamer. Has these. There are people who can balance these things, but. There are also a lot of mental health issues that have cropped up because of gaming as well. So I think it's important to think very thoughtfully about the way we balance technology. And the way we live, our lives. But I think. With. The. I think. With. The AI companion thing in particular. What's particularly worrying about this or like maybe the difference between AI convenience and gaming is the fact that. A companions kind of. Has a broader impact on how we see people. Maybe. I mean, there's been a lot of things about desensitized. Desensitization. Because of gaming. And because you're exposed to all these kind of violence environments, constantly. And that's probably been like a real issue that has cropped up. And we might see that with AI as well. No? Yeah. I think I fully agree with that. There are many risks, that. We have taken by blindly, like, letting things happen, I guess like, games or like, say, having porn happen was like this huge change that now you literally have, like, can imagine having sex with like, millions of people, literally, like, at the click of a button, like anyone you want. And we're still not fully grasp of that. And I think it will get even crazier with AI. But I guess I would say that just because. It's a dangerous road. A possibly dangerous one. Doesn't mean that we shouldn't try it because I guess. If we agree that. It's objectively better in certain ways, and that we can engineer it to be so then. We should. Work to somehow. Test it out in a safe way? Roll it out in a safe way. And ultimately help a lot of people because we are releasing this and there is a potential to help a lot of people. But there's also the potential of like, oh, yeah, ethical issues like you said. And also. Birth rate issues. Yeah. I think at least in the long term I feel like definitely like AI girlfriends. Have the ability to be a lot better. Than biological ones better than biological. In certain ways. Again like being available all the time. Like never. Needing support, I guess. You can rely on this thing to always support you, and you need to put not that much effort into maintaining it, I guess. I think that's a big thing for a lot of people. And there's just like this deep connection you can form with that thing. Yeah.  It stopped again. The recording started. Okay.  Yes, it's gone. Okay. So I don't know if I necessarily agree with. Ai companions being better than biological ones just because. They have this availability. This unconditionality. I don't know if that availability and unconditionality. Is necessarily healthy for us. And I don't know. Maybe can have some warping effect on the way we see people and the way we see relationships, especially when there's something out there like this that mimics it so closely. I wish I had the sunrise feature. Can you. Just the T shirt points. Yeah. Let me summarize what I did, okay. The speaker is skeptical of our air companions being better than biological ones, as she believes the unconditional availability might not be healthy for us and can work the way we see relationships. Mimicking human relationships closely can have implications on the Wimbussie people. How does it know? I'm a girl? I don't know. Biased. We actually don't know what point. Or what. Or what is the point. I believe that unconditional availability might not be healthy for us and can Warp the way like in general. Yeah.  I think. There are many cases of unconditional availability. Or like close to it, I guess. I would say, My family. Is at least in my situation unconditionally like loving and caring and always there. I literally call any one of them with any issue. And they'll always be there for me, I guess. And I guess. I spend. Some time. Maintaining the relationship. But basically all my time is spent at Harvard, like studying stuff, but I find it to be immensely valuable and immensely like reassuring that someone's always there for me. And I think this is very much a similar thing. And once you grow up and your parents are gone. Right. And. You have to grapple with life. When it gets harder and harder and you don't have this family to support you. Why don't we just have this right. Why not ensure this for everyone and for those without good family. I was lucky to have. Force them to live. Like they do. You know what I mean. And then you make a lot of good points. But I just want to say this thing also thinks that you're a girl. Okay.  Here's. The thing. I feel as if. You say that you receive. A lot. Unconditionality in your life. But I don't know if that's necessarily true. Is your family truly unconditional? I mean, they still have their own needs. They're not there for you. Instantly. And unconditionally, like AI is. I think as much as we say family love is unconditional. I mean, I still think there's some conditions, right? Because these were human. Maybe well, yes, but I would say. It's not unconditional. There's always a condition. To have an AI girlfriend, there's the condition that you own a computer, right? But to have my family, there's the condition that. I call them once in a while or I come back every semester or so, right. There's always those conditions. But I'm saying that. It's so close and unconditional. That I would say with an AI, there would be almost no functional difference other than. I visit my family every few months. Yeah, that's what I'm saying. It's not perfectly unconditional, but there's never anything perfectly unconditional. I guess. Yeah, I agree that nothing is perfectly unconditional, but I feel as if AI is much closer to unconditionally your family is because potentially you can treat your AI companion like really badly, and it just wouldn't matter. What impact does it have. Isn't that enough? Yeah. I'm interested. Now. I'm interested in the conversation. It was kind of hard to pay attention to the conversation because I was trying to make the demo good. Get good clips. Yeah, I think so. We need to stick fact check. It keeps saying that there were no factual things said, yeah, we should just have it be like, look up what they said. Well, it can't. Yeah.  A dangerous road. A possibly dangerous one doesn't mean that we shouldn't try it. You can't look these up. Oh, yeah, I mean. But it looked up, like replica. No. This is just gpt four. They can't access the Internet. It just knew it. Okay. But that's the same thing, right? Yeah. Real time. I mean, it's just like, not. Yeah. So it's the same thing, right. We talk more. Well, we just have to change it. So that when we prompt it, it. 'll. Say that it won't annoy us, I guess. Yeah. About the last few sentences or something. Could you tell or like. Did you also feel like you couldn't really follow the conversation as easy. Or like the interface is almost clunky and overstimulating. I thought that it was very useful. What I felt was I kept triggering things by accident. Yeah. Did you Resize it to be bigger than Reg it's two A, is it? Yeah. Oh, my God. Okay. Wait. So I think that like, okay, there's several things about this. So first. I felt like I was triggering things by accident. Second of all. It was useful, though it was actually very useful. Open this. Let me just no. Yeah. Keep going. I felt like it was useful. I was triggering things by accident. And that made it hard. Yeah. But I think. By default the boxes should be further from each other. Yeah. We can use that for them. Let's use them. You definitely need to be trained on using it before using it.  Yes. That's what I was saying. Because it takes a while to get good at it. If you had experience using it. It would be really useful. We're going to have that mock thing, which. We will figure out tomorrow. But yeah, I'm glad you found it useful too. It was really useful. This paragraph needs to be a bit longer, I think. There's just like a few more quality of life things. And. I wouldn't really like to use this. I think bullet points are better. Yeah, I think that we should not have. Yeah. I changed the third one to bullet points and. Yeah, it's just easier to read and skim and then. You don't want to verbatim. Repeat. You don't want a verbatim. Repeat. Like everything the model says. You want to see the main thoughts and extrapolates. I think.  Is this a startup? Yeah. Can we start a stop? Yeah.  Or. Did you already raise a million dollars with homex. I raised $7,000. 7000.   Dude. Mikayla is going to be in New York. You'll be in New York? What am I going to do here? I don't know anyone here. Arian. Yeah. Or he's not interested in building. This kind of stuff. I guess, really. Actually, I am interested in building this house. I would like to continue building. I want to continue working. Then we should. What's the next. Project the next one. I feel like this one can be refined a lot. Yeah. There's a lot of. Or we could totally spend a few weeks, like, making this really, really good. That's true. I don't know. I'm looking to keep my amount of projects low. And make them really good. I've always thought that if you're going to focus on less. Yeah. If you guys focus on making something very good, you guys could have something very good. If you guys weren't. Constantly stretched between. Ten things. That are all done kind of Yes. I'm sorry. Yes. But Yeah. I like to work on things. I think it's a lot of fun. Let's upload these videos.   The rise. New folder. Fuck. Okay. I got you, bro.  I've had a lot of fun this week. I think this project is really fun too. Even after going through. Five or six. Seniorization models. That's nice. Let's go to sleep now. Okay, they're uploaded so we can edit them tomorrow or something. Open tomorrow. I will be spending the entire day on project really. Going to be at the Designs. There. I don't think I can see the whole time. If I want to pass this class anyway, but what do I hear about Grace? Right. You don't. Who. Needs graves period. Oh shit. Also. Your sewage is full. Is this your drive. Is this Harvard. Yeah. God. I like the name. It is clever, but. It's really hard to say. Delete this one.  There's a lot of. Huge.    I think we can make a better demo. Wait. What. I think we can make a better demo. Than what we did today. I think we should continue playing with it. Yeah. See what it does. But we need some fuck me. Measure. 